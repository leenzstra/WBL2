
<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<title>dev09: Go Coverage Report</title>
		<style>
			body {
				background: black;
				color: rgb(80, 80, 80);
			}
			body, pre, #legend span {
				font-family: Menlo, monospace;
				font-weight: bold;
			}
			#topbar {
				background: black;
				position: fixed;
				top: 0; left: 0; right: 0;
				height: 42px;
				border-bottom: 1px solid rgb(80, 80, 80);
			}
			#content {
				margin-top: 50px;
			}
			#nav, #legend {
				float: left;
				margin-left: 10px;
			}
			#legend {
				margin-top: 12px;
			}
			#nav {
				margin-top: 10px;
			}
			#legend span {
				margin: 0 5px;
			}
			.cov0 { color: rgb(192, 0, 0) }
.cov1 { color: rgb(128, 128, 128) }
.cov2 { color: rgb(116, 140, 131) }
.cov3 { color: rgb(104, 152, 134) }
.cov4 { color: rgb(92, 164, 137) }
.cov5 { color: rgb(80, 176, 140) }
.cov6 { color: rgb(68, 188, 143) }
.cov7 { color: rgb(56, 200, 146) }
.cov8 { color: rgb(44, 212, 149) }
.cov9 { color: rgb(32, 224, 152) }
.cov10 { color: rgb(20, 236, 155) }

		</style>
	</head>
	<body>
		<div id="topbar">
			<div id="nav">
				<select id="files">
				
				<option value="file0">dev09/task.go (72.5%)</option>
				
				</select>
			</div>
			<div id="legend">
				<span>not tracked</span>
			
				<span class="cov0">not covered</span>
				<span class="cov8">covered</span>
			
			</div>
		</div>
		<div id="content">
		
		<pre class="file" id="file0" style="display: none">package main

import (
        "bytes"
        "flag"
        "fmt"
        "io"
        "net/http"
        "net/url"
        "os"
        "path/filepath"
        "strings"
        "sync"

        "github.com/PuerkitoBio/goquery"
)

/*
=== Утилита wget ===

Реализовать утилиту wget с возможностью скачивать сайты целиком

Программа должна проходить все тесты. Код должен проходить проверки go vet и golint.
*/

const (
        // Глубина рекурсии/ссылок
        defaultDepth = -1
        // Исходная ссылка
        defaultUrl = ""
        // Путь сохранения
        defaultDir = "."
        // Конкурентный запуск
        defaultConcur = false
)

var (
        verbose = false
)

// Ссылка и ее глубина от исходной
type linkDepth struct {
        url   string
        Depth int
}

type wget struct {
        url   *url.URL
        dir   string
        depth int

        // Посещенные ссылки
        visited map[string]struct{}
}

func NewWget(url *url.URL, dir string, depth int) *wget <span class="cov8" title="1">{
        return &amp;wget{
                url:     url,
                dir:     dir,
                depth:   depth,
                visited: make(map[string]struct{}),
        }
}</span>

// Запуск конкурентного скачивания сайта
func (w *wget) RunAsync() error <span class="cov8" title="1">{
        // канал, в который приходят все ссылки
        linksChan := make(chan linkDepth)
        errors := make(chan error)
        wg := sync.WaitGroup{}

        // Запуск первой ссылки
        wg.Add(1)
        go func() </span><span class="cov8" title="1">{
                err := w.runAsync(linkDepth{w.url.String(), w.depth}, linksChan, &amp;wg)
                if err != nil </span><span class="cov8" title="1">{
                        errors &lt;- err
                }</span>
        }()

        // Закрытие канала, когда закончили работу
        <span class="cov8" title="1">go func() </span><span class="cov8" title="1">{
                wg.Wait()
                close(linksChan)
                close(errors)
        }</span>()

        // Получаем ссылки из канала
        // Проверяем были ли уже там
        // Если не были, то отмечаемся, уменьшаем глубину и идем глубже по сайту
        <span class="cov8" title="1">go func() </span><span class="cov8" title="1">{
                for link := range linksChan </span><span class="cov8" title="1">{
                        if _, ok := w.visited[link.url]; !ok </span><span class="cov8" title="1">{
                                w.visited[link.url] = struct{}{}
                                if link.Depth &gt; 0 </span><span class="cov8" title="1">{
                                        link.Depth = link.Depth - 1
                                }</span>
                                <span class="cov8" title="1">wg.Add(1)
                                go func() </span><span class="cov8" title="1">{
                                        err := w.runAsync(link, linksChan, &amp;wg)
                                        if err != nil </span><span class="cov0" title="0">{
                                                errors &lt;- err
                                        }</span>
                                }()
                        }
                }
        }()

        <span class="cov8" title="1">return &lt;-errors</span>
}

// Реализация конкурентного запуска
func (w *wget) runAsync(root linkDepth, linksChan chan&lt;- linkDepth, wg *sync.WaitGroup) error <span class="cov8" title="1">{
        defer wg.Done()

        // Получение ссылок из html
        links, err := w.run(root.url, root.Depth)
        if err != nil </span><span class="cov8" title="1">{
                return err
        }</span>

        // Запись ссылок в общий канал
        <span class="cov8" title="1">for _, link := range links </span><span class="cov8" title="1">{
                linksChan &lt;- linkDepth{link, root.Depth}
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// Синхронный/последовательный запуск скачивания сайта
func (w *wget) RunSync() error <span class="cov8" title="1">{
        return w.runSync(w.url.String(), w.depth+1)
}</span>

// Реализация синхронного запуска
// Используется рекурсия
func (w *wget) runSync(root string, depth int) error <span class="cov8" title="1">{
        // Получаем ссылки из html
        links, err := w.run(root, depth)
        if err != nil </span><span class="cov8" title="1">{
                return err
        }</span>

        // Проверяем, были ли уже там
        // Если нет, то идем глубже
        <span class="cov8" title="1">for _, link := range links </span><span class="cov8" title="1">{
                if _, ok := w.visited[link]; !ok </span><span class="cov8" title="1">{
                        w.visited[link] = struct{}{}

                        var err error
                        if depth &gt; 0 </span><span class="cov8" title="1">{
                                err = w.runSync(link, depth-1)
                        }</span> else<span class="cov0" title="0"> {
                                err = w.runSync(link, depth)
                        }</span>

                        <span class="cov8" title="1">if err != nil </span><span class="cov0" title="0">{
                                return err
                        }</span>
                }
        }

        <span class="cov8" title="1">return nil</span>
}

// Главная функция обработки html документа
// И получения из него ссылок
func (w *wget) run(root string, depth int) ([]string, error) <span class="cov8" title="1">{
        // Если достигли максимальной глубины, то конец
        if depth == 0 </span><span class="cov8" title="1">{
                return []string{}, nil
        }</span>

        <span class="cov8" title="1">if verbose </span><span class="cov0" title="0">{
                fmt.Println("Visit", root, "depth", depth)
        }</span>

        // Получем html
        <span class="cov8" title="1">p, err := w.download(root)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>

        <span class="cov8" title="1">url, err := url.Parse(root)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        // Парсим html
        <span class="cov8" title="1">doc, err := w.parseHtml(bytes.NewReader(p))
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        // Сохранаяем документ
        <span class="cov8" title="1">err = w.save(url.Path, bytes.NewReader(p))
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        // Ищем все ссылки
        <span class="cov8" title="1">links, err := w.findLinks(doc)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov8" title="1">return links, nil</span>
}

// Получение html документа
func (w *wget) download(url string) ([]byte, error) <span class="cov8" title="1">{
        res, err := http.Get(url)
        if err != nil </span><span class="cov8" title="1">{
                return nil, err
        }</span>

        <span class="cov8" title="1">defer res.Body.Close()
        if res.StatusCode != 200 </span><span class="cov8" title="1">{
                return nil, err
        }</span>

        <span class="cov8" title="1">return io.ReadAll(res.Body)</span>
}

// Парсинг html документа
func (w *wget) parseHtml(html io.Reader) (*goquery.Document, error) <span class="cov8" title="1">{
        doc, err := goquery.NewDocumentFromReader(html)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov8" title="1">return doc, nil</span>
}

// Сохранение html документа
func (w *wget) save(url string, body io.Reader) error <span class="cov8" title="1">{
        if strings.HasSuffix(url, "/") </span><span class="cov8" title="1">{
                url += "index"
        }</span>

        <span class="cov8" title="1">p := filepath.Join(w.dir, url+".html")
        if err := os.MkdirAll(filepath.Dir(p), 0770); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov8" title="1">file, err := os.Create(p)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">defer file.Close()

        _, err = io.Copy(file, body)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// Получение ссылок из html
func (w *wget) findLinks(doc *goquery.Document) ([]string, error) <span class="cov8" title="1">{
        links := make([]string, 0)

        doc.Find("a[href]").Each(func(i int, s *goquery.Selection) </span><span class="cov8" title="1">{
                href, _ := s.Attr("href")
                if strings.HasPrefix(href, "/") </span><span class="cov8" title="1">{
                        u, err := url.Parse(href)
                        if err != nil </span><span class="cov0" title="0">{
                                return
                        }</span>
                        <span class="cov8" title="1">href, _ = url.JoinPath(w.url.String(), u.Path)
                        links = append(links, href)</span>
                }
        })

        <span class="cov8" title="1">return links, nil</span>
}

func main() <span class="cov0" title="0">{
        var (
                // Ссылка на сайт, директория сохранения файов
                siteUrl, dir string
                // Макс. глубина рекурсии
                depth int
                // паралелльная работа
                concur  bool
                verbose bool
        )

        flag.StringVar(&amp;siteUrl, "url", defaultUrl, "root url")
        flag.StringVar(&amp;dir, "dir", defaultUrl, "save dir")
        flag.IntVar(&amp;depth, "depth", defaultDepth, "max recurstion depth")
        flag.BoolVar(&amp;concur, "conc", defaultConcur, "run concurrent")
        flag.BoolVar(&amp;verbose, "v", verbose, "verbose")

        flag.Parse()

        if siteUrl == "" </span><span class="cov0" title="0">{
                fmt.Println("no url provided")
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">u, err := url.Parse(siteUrl)
        if err != nil </span><span class="cov0" title="0">{
                fmt.Println(err)
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">wget := NewWget(u, dir, depth)

        if concur </span><span class="cov0" title="0">{
                err = wget.RunAsync()
        }</span> else<span class="cov0" title="0"> {
                err = wget.RunSync()
        }</span>

        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                fmt.Println(err)
        }</span>
}
</pre>
		
		</div>
	</body>
	<script>
	(function() {
		var files = document.getElementById('files');
		var visible;
		files.addEventListener('change', onChange, false);
		function select(part) {
			if (visible)
				visible.style.display = 'none';
			visible = document.getElementById(part);
			if (!visible)
				return;
			files.value = part;
			visible.style.display = 'block';
			location.hash = part;
		}
		function onChange() {
			select(files.value);
			window.scrollTo(0, 0);
		}
		if (location.hash != "") {
			select(location.hash.substr(1));
		}
		if (!visible) {
			select("file0");
		}
	})();
	</script>
</html>
